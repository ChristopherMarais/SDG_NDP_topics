{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e6e331b6-e00f-4592-b44b-ef5031439bad",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-10-15T02:19:32.742856Z",
     "iopub.status.busy": "2022-10-15T02:19:32.742856Z",
     "iopub.status.idle": "2022-10-15T02:19:39.727401Z",
     "shell.execute_reply": "2022-10-15T02:19:39.726401Z",
     "shell.execute_reply.started": "2022-10-15T02:19:32.742856Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "from bertopic import BERTopic\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "81c62921-cb96-457d-9d9e-6359f5761be5",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-10-15T02:19:39.728391Z",
     "iopub.status.busy": "2022-10-15T02:19:39.728391Z",
     "iopub.status.idle": "2022-10-15T02:19:40.006401Z",
     "shell.execute_reply": "2022-10-15T02:19:40.005401Z",
     "shell.execute_reply.started": "2022-10-15T02:19:39.728391Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# import data\n",
    "# data_df = pd.read_csv('C:\\\\Users\\\\gcmar\\\\Desktop\\\\GIT_REPOS\\\\LAB\\\\Literature_summary\\\\Papers\\\\scopus_bark_ambrosia_beetles.csv')\n",
    "# data_df['text'] = data_df['Title'].apply(str) + data_df['Author Keywords'].apply(str) + data_df['Index Keywords'].apply(str) + data_df['Abstract'].apply(str) \n",
    "# data_df['topic_text'] = data_df['Title'].apply(str) + data_df['Author Keywords'].apply(str) + data_df['Index Keywords'].apply(str)\n",
    "# docs = data_df['text'].dropna().tolist()\n",
    "# topic_docs = data_df['topic_text'].dropna().tolist()\n",
    "\n",
    "# # file_lst = data_df['file'].unique()\n",
    "# for j in file_lst:\n",
    "#     try:\n",
    "#         print('_______________________________\\n\\n', j)\n",
    "#         df = data_df[data_df['file']==j]\n",
    "#         for i in range(start_point, len(df), win_size):\n",
    "#             coref_series = coref_res(text_series=df[\"text\"].iloc[i:i+win_size])\n",
    "#             print('coref done', i, '-', i+win_size)\n",
    "#             link_entities_series = link_entities(text_series=coref_series)\n",
    "#             print('entity linking done', i, '-', i+win_size)\n",
    "#             entities_df = pd.concat(link_entities_series.tolist())\n",
    "#             print('df create done', i, '-', i+win_size)\n",
    "#             entities_df_lst.append(entities_df)\n",
    "#             print('df to list done', i, '-', i+win_size, '\\n')\n",
    "#         all_entities_df = pd.concat(entities_df_lst)\n",
    "#         all_entities_df.reset_index(drop=True, inplace=True)\n",
    "#         edge_lst_df = all_entities_df.value_counts().reset_index().rename(columns={0: \"count\"})\n",
    "#         edge_lst_df.to_csv('entity_weighted_edgelist_ALL_'+j[:-4]+'.csv')\n",
    "#         edge_lst_df.to_feather('entity_weighted_edgelist_ALL_'+j[:-4]+'.feather')\n",
    "#     except:\n",
    "#         print(\"DID NOT WORK WITH - \", j)\n",
    "\n",
    "pwd = os.getcwd()\n",
    "data_path = os.path.dirname(pwd) + \"\\\\Data\\\\NDPs\\\\\"\n",
    "data_df = pd.read_feather(data_path+\"Africa_docs.feather\")\n",
    "data_df = data_df.drop_duplicates().reset_index(drop=True)\n",
    "data_df[\"text\"] = data_df[\"text\"].astype(str)\n",
    "data_df['text'] = data_df['text'].str.strip()\n",
    "data_df['text'] = data_df['text'].str.split('. \\n') # OR '. \\n'\n",
    "data_df = data_df.explode('text').reset_index(drop=True)\n",
    "# docs = data_df['text'].dropna().tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "580982bc-b186-4370-bb2d-ac16d1db2421",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-10-15T02:19:40.008392Z",
     "iopub.status.busy": "2022-10-15T02:19:40.008392Z",
     "iopub.status.idle": "2022-10-15T02:19:40.020380Z",
     "shell.execute_reply": "2022-10-15T02:19:40.020380Z",
     "shell.execute_reply.started": "2022-10-15T02:19:40.008392Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "emb_model = \"multi-qa-mpnet-base-dot-v1\" # \"all-mpnet-base-v2\" OR multi-qa-mpnet-base-dot-v1  OR \"xlm-r-bert-base-nli-stsb-mean-tokens\"\n",
    "model = BERTopic(embedding_model=emb_model, nr_topics=\"auto\", top_n_words=15, min_topic_size=3) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "58379d03-9447-4289-a3a2-a06679f1a960",
   "metadata": {},
   "source": [
    "#### Topics per doc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c56408c1-8ee7-4437-a5ed-328e0066aa0f",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-10-15T02:19:40.022382Z",
     "iopub.status.busy": "2022-10-15T02:19:40.021381Z",
     "iopub.status.idle": "2022-10-15T02:30:22.836955Z",
     "shell.execute_reply": "2022-10-15T02:30:22.835961Z",
     "shell.execute_reply.started": "2022-10-15T02:19:40.022382Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Botswana NDP.pdf STARTED\n",
      "fixing doc lengths\n",
      "applying model\n",
      "Botswana NDP.pdf DONE \n",
      "_________________\n",
      "\n",
      "Botswana VNR.pdf STARTED\n",
      "fixing doc lengths\n",
      "applying model\n",
      "Botswana VNR.pdf DONE \n",
      "_________________\n",
      "\n",
      "Cameroon MDP.pdf STARTED\n",
      "fixing doc lengths\n",
      "applying model\n",
      "Cameroon MDP.pdf DONE \n",
      "_________________\n",
      "\n",
      "Cameroon NDP.pdf STARTED\n",
      "fixing doc lengths\n",
      "applying model\n",
      "Cameroon NDP.pdf DONE \n",
      "_________________\n",
      "\n",
      "Eswatini NDP.pdf STARTED\n",
      "fixing doc lengths\n",
      "applying model\n",
      "Eswatini NDP.pdf DONE \n",
      "_________________\n",
      "\n",
      "Eswatini VNR.pdf STARTED\n",
      "fixing doc lengths\n",
      "applying model\n",
      "data size too small to run properly\n",
      "Eswatini VNR.pdf DONE \n",
      "_________________\n",
      "\n",
      "Gambia NDP.pdf STARTED\n",
      "fixing doc lengths\n",
      "applying model\n",
      "data size too small to run properly\n",
      "Gambia NDP.pdf DONE \n",
      "_________________\n",
      "\n",
      "Gambia VNR.pdf STARTED\n",
      "fixing doc lengths\n",
      "applying model\n",
      "Gambia VNR.pdf DONE \n",
      "_________________\n",
      "\n",
      "Ghana MDP.pdf STARTED\n",
      "fixing doc lengths\n",
      "applying model\n",
      "Ghana MDP.pdf DONE \n",
      "_________________\n",
      "\n",
      "Ghana NDP.pdf STARTED\n",
      "fixing doc lengths\n",
      "applying model\n",
      "Ghana NDP.pdf DONE \n",
      "_________________\n",
      "\n",
      "Ghana VNR.pdf STARTED\n",
      "fixing doc lengths\n",
      "applying model\n",
      "data size too small to run properly\n",
      "Ghana VNR.pdf DONE \n",
      "_________________\n",
      "\n",
      "Kenya MDP.pdf STARTED\n",
      "fixing doc lengths\n",
      "applying model\n",
      "Kenya MDP.pdf DONE \n",
      "_________________\n",
      "\n",
      "Kenya NDP.pdf STARTED\n",
      "fixing doc lengths\n",
      "applying model\n",
      "data size too small to run properly\n",
      "Kenya NDP.pdf DONE \n",
      "_________________\n",
      "\n",
      "Kenya VNR.pdf STARTED\n",
      "fixing doc lengths\n",
      "applying model\n",
      "Kenya VNR.pdf DONE \n",
      "_________________\n",
      "\n",
      "Liberia MDP.pdf STARTED\n",
      "fixing doc lengths\n",
      "applying model\n",
      "Liberia MDP.pdf DONE \n",
      "_________________\n",
      "\n",
      "Liberia NDP.pdf STARTED\n",
      "fixing doc lengths\n",
      "applying model\n",
      "data size too small to run properly\n",
      "Liberia NDP.pdf DONE \n",
      "_________________\n",
      "\n",
      "Liberia VNR.pdf STARTED\n",
      "fixing doc lengths\n",
      "applying model\n",
      "data size too small to run properly\n",
      "Liberia VNR.pdf DONE \n",
      "_________________\n",
      "\n",
      "Malawi NDP.pdf STARTED\n",
      "fixing doc lengths\n",
      "applying model\n",
      "Malawi NDP.pdf DONE \n",
      "_________________\n",
      "\n",
      "Malawi VNR.pdf STARTED\n",
      "fixing doc lengths\n",
      "applying model\n",
      "data size too small to run properly\n",
      "Malawi VNR.pdf DONE \n",
      "_________________\n",
      "\n",
      "Namibia MDP.pdf STARTED\n",
      "fixing doc lengths\n",
      "applying model\n",
      "data size too small to run properly\n",
      "Namibia MDP.pdf DONE \n",
      "_________________\n",
      "\n",
      "Namibia NDP.pdf STARTED\n",
      "fixing doc lengths\n",
      "applying model\n",
      "data size too small to run properly\n",
      "Namibia NDP.pdf DONE \n",
      "_________________\n",
      "\n",
      "Namibia VNR.pdf STARTED\n",
      "fixing doc lengths\n",
      "applying model\n",
      "Namibia VNR.pdf DONE \n",
      "_________________\n",
      "\n",
      "Nigeria NDP.pdf STARTED\n",
      "fixing doc lengths\n",
      "applying model\n",
      "Nigeria NDP.pdf DONE \n",
      "_________________\n",
      "\n",
      "Nigeria VNR.pdf STARTED\n",
      "fixing doc lengths\n",
      "applying model\n",
      "Nigeria VNR.pdf DONE \n",
      "_________________\n",
      "\n",
      "Rwanda NDP.pdf STARTED\n",
      "fixing doc lengths\n",
      "applying model\n",
      "Rwanda NDP.pdf DONE \n",
      "_________________\n",
      "\n",
      "Rwanda VNR.pdf STARTED\n",
      "fixing doc lengths\n",
      "applying model\n",
      "Rwanda VNR.pdf DONE \n",
      "_________________\n",
      "\n",
      "South Africa NDP.pdf STARTED\n",
      "fixing doc lengths\n",
      "applying model\n",
      "South Africa NDP.pdf DONE \n",
      "_________________\n",
      "\n",
      "South Africa VNR.pdf STARTED\n",
      "fixing doc lengths\n",
      "applying model\n",
      "South Africa VNR.pdf DONE \n",
      "_________________\n",
      "\n",
      "Soutn Africa MDP.pdf STARTED\n",
      "fixing doc lengths\n",
      "applying model\n",
      "Soutn Africa MDP.pdf DONE \n",
      "_________________\n",
      "\n",
      "Tanzania MDP.pdf STARTED\n",
      "fixing doc lengths\n",
      "applying model\n",
      "Tanzania MDP.pdf DONE \n",
      "_________________\n",
      "\n",
      "Tanzania NDP.pdf STARTED\n",
      "fixing doc lengths\n",
      "applying model\n",
      "Tanzania NDP.pdf DONE \n",
      "_________________\n",
      "\n",
      "Togo NDP.pdf STARTED\n",
      "fixing doc lengths\n",
      "applying model\n",
      "data size too small to run properly\n",
      "Togo NDP.pdf DONE \n",
      "_________________\n",
      "\n",
      "Togo VNR.pdf STARTED\n",
      "fixing doc lengths\n",
      "applying model\n",
      "Togo VNR.pdf DONE \n",
      "_________________\n",
      "\n",
      "Zambia NDP.pdf STARTED\n",
      "fixing doc lengths\n",
      "applying model\n",
      "Zambia NDP.pdf DONE \n",
      "_________________\n",
      "\n",
      "Zambia VNR.pdf STARTED\n",
      "fixing doc lengths\n",
      "applying model\n",
      "Zambia VNR.pdf DONE \n",
      "_________________\n",
      "\n",
      "Zimbabwe NDP.pdf STARTED\n",
      "fixing doc lengths\n",
      "applying model\n",
      "Zimbabwe NDP.pdf DONE \n",
      "_________________\n",
      "\n",
      "Zimbabwe VNR.pdf STARTED\n",
      "fixing doc lengths\n",
      "applying model\n",
      "Zimbabwe VNR.pdf DONE \n",
      "_________________\n",
      "\n"
     ]
    }
   ],
   "source": [
    "finished_lst = []\n",
    "# for file in os.listdir(os.getcwd()):\n",
    "#     filename = os.fsdecode(file)\n",
    "#     if filename.endswith(\".html\"):\n",
    "#         finished_lst.append(filename)\n",
    "        \n",
    "file_lst = data_df['file'].unique()       \n",
    "for i in file_lst:\n",
    "    if i[:-4]+'_'+emb_model+'_topics.html' in finished_lst:\n",
    "        print(i, \"FOUND\", \"\\n_________________\\n\")\n",
    "    else:\n",
    "        print(i, \"STARTED\")\n",
    "        \n",
    "        # select only text from one pdf\n",
    "        docs = data_df[data_df['file']==i]['text'].str.strip().dropna().tolist()\n",
    "        # decrease the max number of words in items in docs\n",
    "        print(\"fixing doc lengths\")\n",
    "        # new_docs = []\n",
    "        # for str_val in docs:\n",
    "        #     if len(str_val.split(\" \")) > 512:\n",
    "        #         new_docs.append(str_val.split(\"\\n\"))\n",
    "        #     else:\n",
    "        #         new_docs.append(str_val)\n",
    "        # new_docs_flat = [item for sublist in new_docs for item in sublist]\n",
    "        # docs = new_docs_flat\n",
    "        \n",
    "        # increase number of items in docs if number is too small\n",
    "        if len(docs)<20:\n",
    "            docs_new = []\n",
    "            for str_val in docs:\n",
    "                docs_new += str_val.split('\\n')\n",
    "                docs = docs_new\n",
    "        # estiamte topics and probabilities\n",
    "        print(\"applying model\")\n",
    "        try:\n",
    "            model = BERTopic(embedding_model=emb_model, nr_topics=\"auto\", top_n_words=15, min_topic_size=3)\n",
    "            topics, probabilities = model.fit_transform(docs)\n",
    "        except: \n",
    "            model = BERTopic(embedding_model=emb_model, nr_topics=10, top_n_words=15, min_topic_size=3)\n",
    "            topics, probabilities = model.fit_transform(docs)\n",
    "            print(\"reduced topics as text was too small\")\n",
    "        # get topic counts and probabilities in one dataframe\n",
    "        topic_prob_df = pd.DataFrame([topics, probabilities]).T\n",
    "        topic_prob_mean_df = topic_prob_df.groupby([0]).mean(1).reset_index().sort_values(0)\n",
    "        topic_count_s = topic_prob_df[0].value_counts().sort_index()\n",
    "        topic_prob_mean_df['count'] = topic_count_s.to_list()\n",
    "        topic_prob_mean_df.columns = ['topic', 'probability', 'count']\n",
    "        # add topic words column\n",
    "        topic_df = pd.DataFrame(np.array(list(model.topic_representations_.values()))[:,:,0])\n",
    "        topic_df['topic_words'] = topic_df[topic_df.columns].apply(lambda row: ' '.join(row.values.astype(str)), axis=1)\n",
    "        topic_df['topic'] = list(model.topic_representations_)\n",
    "        topic_df['topic_words'][0] = None\n",
    "        topic_df = topic_df[['topic', 'topic_words']]\n",
    "        topic_prob_mean_df = topic_prob_mean_df.merge(topic_df,how='left', on='topic')\n",
    "        # create visualization\n",
    "        try:\n",
    "            fig = model.visualize_topics()\n",
    "            fig.write_html(i[:-4]+'_'+emb_model+'_topics.html')\n",
    "            topic_prob_mean_df.to_csv(i[:-4]+'_'+emb_model+'_topics.csv', index=False)\n",
    "        except:\n",
    "            print(\"data size too small to run properly\")\n",
    "            topic_prob_mean_df.to_csv(i[:-4]+'_'+emb_model+'_topics_TooShort.csv', index=False)\n",
    "        print(i, \"DONE\", \"\\n_________________\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "720e087f-260e-4011-9486-ab4bc1a7505c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88ddbc28-3511-4a70-83f1-846b4134a20f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07d721f5-e36e-4b2d-818f-ccdbe10712e6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57c452a9-cc8e-42d0-b215-6c543dd0041d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "188c71aa-80a1-46bb-b9c8-2baa7d0f3d7f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1197c239-c1bb-4770-804c-9af002a91ae3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b7b5164-4286-49bf-8440-9d7a586cbd0c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97644345-df94-4363-8ae8-1d634b3a42e7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd678dc5-c72e-4b46-9890-f3c93939727c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61e700a0-1f7b-4ab6-b25c-6c134b5d3122",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12e81d49-e30e-4c72-8f7d-139106faa364",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e592dce-3334-4f3d-a200-fbdb96c374c1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b0e4b9f-2a21-44dd-96ca-4b377a6ab20c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86390881-e672-4d61-b2a5-c1a3467fa3a0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ba49083-cb44-4153-9c2a-7e8a20d26c76",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81df6e38-cf63-40ff-8c6c-c8d1f25a22e5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f12ddae-a9d0-4ce2-b0ad-fa4512860203",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b23da42-334e-4c0f-b1d9-b4a1c778fe74",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "fa2bc53e-03f2-4a01-bf7e-a8c9d9bd2b02",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-10-15T02:30:22.837961Z",
     "iopub.status.busy": "2022-10-15T02:30:22.837961Z",
     "iopub.status.idle": "2022-10-15T02:30:22.852959Z",
     "shell.execute_reply": "2022-10-15T02:30:22.851968Z",
     "shell.execute_reply.started": "2022-10-15T02:30:22.837961Z"
    }
   },
   "outputs": [],
   "source": [
    "#######################################################################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d971540b-e7cc-460e-97ae-26d9f7c6c69b",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-10-15T02:30:22.855964Z",
     "iopub.status.busy": "2022-10-15T02:30:22.854964Z",
     "iopub.status.idle": "2022-10-15T02:30:22.868960Z",
     "shell.execute_reply": "2022-10-15T02:30:22.867954Z",
     "shell.execute_reply.started": "2022-10-15T02:30:22.855964Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# data_df['topic'] = topics\n",
    "# data_df['topic_prob'] = probabilities.tolist()\n",
    "\n",
    "# # add topic words column\n",
    "# topic_df = pd.DataFrame(np.array(list(model.topic_representations_.values()))[:,:,0])\n",
    "# topic_df['topic_words'] = topic_df[topic_df.columns].apply(lambda row: ' '.join(row.values.astype(str)), axis=1)\n",
    "# topic_df['topic'] = list(model.topic_representations_)\n",
    "# topic_df['topic_words'][0] = None\n",
    "# topic_df = topic_df[['topic', 'topic_words']]\n",
    "# data_df.merge(topic_df,how='left', on='topic')\n",
    "\n",
    "# data_df.to_csv('papers_bertopic.csv', index=False)\n",
    "# data_df.to_feather('papers_bertopic.feather', index=False)\n",
    "\n",
    "# model.get_topic_info()\n",
    "\n",
    "# fig = model.visualize_topics()\n",
    "# fig.write_html(\"topics_viz.html\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb4a8d8d-e80d-4071-8c07-bf57b445a4cf",
   "metadata": {},
   "source": [
    "#### Topics over time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ea007dd1-f398-421a-9598-572d3a225864",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-10-15T02:30:22.870959Z",
     "iopub.status.busy": "2022-10-15T02:30:22.869957Z",
     "iopub.status.idle": "2022-10-15T02:30:22.884979Z",
     "shell.execute_reply": "2022-10-15T02:30:22.883976Z",
     "shell.execute_reply.started": "2022-10-15T02:30:22.870959Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# topics_over_time = model.topics_over_time(docs, timestamps=data_df['Year'].tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f595e49c-6093-4cbc-9374-32af8f47a695",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-10-15T02:30:22.886966Z",
     "iopub.status.busy": "2022-10-15T02:30:22.886966Z",
     "iopub.status.idle": "2022-10-15T02:30:22.900960Z",
     "shell.execute_reply": "2022-10-15T02:30:22.899955Z",
     "shell.execute_reply.started": "2022-10-15T02:30:22.886966Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# fig = model.visualize_topics_over_time(topics_over_time)\n",
    "# fig.write_html(\"topics_over_time.html\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28348b13-f9b0-4e54-a6a3-f0cd26f5ee3d",
   "metadata": {},
   "source": [
    "#### Multiple topics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "63274f84-a50a-424a-a2cb-b10a0cc80606",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-10-15T02:30:22.901965Z",
     "iopub.status.busy": "2022-10-15T02:30:22.901965Z",
     "iopub.status.idle": "2022-10-15T02:30:22.915960Z",
     "shell.execute_reply": "2022-10-15T02:30:22.914965Z",
     "shell.execute_reply.started": "2022-10-15T02:30:22.901965Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# model = BERTopic(embedding_model=\"all-mpnet-base-v2\", nr_topics=\"auto\", top_n_words=5) #\"xlm-r-bert-base-nli-stsb-mean-tokens\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "042d7544-e4d0-42d0-9751-06897e7e998d",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-10-15T02:30:22.917969Z",
     "iopub.status.busy": "2022-10-15T02:30:22.916961Z",
     "iopub.status.idle": "2022-10-15T02:30:22.929961Z",
     "shell.execute_reply": "2022-10-15T02:30:22.929961Z",
     "shell.execute_reply.started": "2022-10-15T02:30:22.917969Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# num_repeats = 5\n",
    "# for i in range(num_repeats):\n",
    "#     topics, probabilities = model.fit_transform(docs)\n",
    "#     data_df['topic_'+str(i)] = topics\n",
    "#     data_df['topic_prob_'+str(i)] = probabilities.tolist()\n",
    "\n",
    "#     # add topic words column\n",
    "#     topic_df = pd.DataFrame(np.array(list(model.topic_representations_.values()))[:,:,0])\n",
    "#     topic_df['topic_words_'+str(i)] = topic_df[topic_df.columns].apply(lambda row: ' '.join(row.values.astype(str)), axis=1)\n",
    "#     topic_df['topic'] = list(model.topic_representations_)\n",
    "#     topic_df['topic_words_'+str(i)][0] = None\n",
    "#     topic_df = topic_df[['topic', 'topic_words_'+str(i)]]\n",
    "#     data_df = data_df.merge(topic_df,how='left', left_on='topic_'+str(i), right_on='topic')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "92f85d69-2bd2-43db-ae42-e59e46097bf0",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-10-15T02:30:22.932959Z",
     "iopub.status.busy": "2022-10-15T02:30:22.931960Z",
     "iopub.status.idle": "2022-10-15T02:30:22.946966Z",
     "shell.execute_reply": "2022-10-15T02:30:22.945968Z",
     "shell.execute_reply.started": "2022-10-15T02:30:22.932959Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# data_df.to_csv('papers_bertopics_multi.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
