{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "963c8478-f33a-4217-86ea-3c42911c0b1f",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "execution": {
     "iopub.execute_input": "2022-10-11T01:22:48.271940Z",
     "iopub.status.busy": "2022-10-11T01:22:48.271440Z",
     "iopub.status.idle": "2022-10-11T01:22:53.056641Z",
     "shell.execute_reply": "2022-10-11T01:22:53.056139Z",
     "shell.execute_reply.started": "2022-10-11T01:22:48.271940Z"
    },
    "id": "BrcXpPzTSszu",
    "outputId": "4af118e9-57bc-4313-f930-9c2348d2f219",
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package omw-1.4 to\n",
      "[nltk_data]     C:\\Users\\GCM\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package omw-1.4 is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "# Add rebel component https://github.com/Babelscape/rebel/blob/main/spacy_component.py\n",
    "import spacy\n",
    "import crosslingual_coreference\n",
    "import requests\n",
    "import re\n",
    "import hashlib\n",
    "import pandas as pd\n",
    "from spacy import Language\n",
    "from typing import List\n",
    "from spacy.tokens import Doc, Span\n",
    "from transformers import pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "63af62f8-d9d2-43f8-8464-f73aaee85eb6",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-10-11T01:22:53.059141Z",
     "iopub.status.busy": "2022-10-11T01:22:53.058642Z",
     "iopub.status.idle": "2022-10-11T01:22:53.088141Z",
     "shell.execute_reply": "2022-10-11T01:22:53.087146Z",
     "shell.execute_reply.started": "2022-10-11T01:22:53.059141Z"
    },
    "id": "cGsgtd8lxhVo",
    "tags": []
   },
   "outputs": [],
   "source": [
    "def call_wiki_api(item):\n",
    "    try:\n",
    "        url = f\"https://www.wikidata.org/w/api.php?action=wbsearchentities&search={item}&language=en&format=json\"\n",
    "        data = requests.get(url).json()\n",
    "        # Return the first id (Could upgrade this in the future)\n",
    "        return data['search'][0]['id']\n",
    "    except:\n",
    "        return 'id-less'\n",
    "\n",
    "def extract_triplets(text):\n",
    "    \"\"\"\n",
    "    Function to parse the generated text and extract the triplets\n",
    "    \"\"\"\n",
    "    triplets = []\n",
    "    relation, subject, relation, object_ = '', '', '', ''\n",
    "    text = text.strip()\n",
    "    current = 'x'\n",
    "    for token in text.replace(\"<s>\", \"\").replace(\"<pad>\", \"\").replace(\"</s>\", \"\").split():\n",
    "        if token == \"<triplet>\":\n",
    "            current = 't'\n",
    "            if relation != '':\n",
    "                triplets.append({'head': subject.strip(), 'type': relation.strip(),'tail': object_.strip()})\n",
    "                relation = ''\n",
    "            subject = ''\n",
    "        elif token == \"<subj>\":\n",
    "            current = 's'\n",
    "            if relation != '':\n",
    "                triplets.append({'head': subject.strip(), 'type': relation.strip(),'tail': object_.strip()})\n",
    "            object_ = ''\n",
    "        elif token == \"<obj>\":\n",
    "            current = 'o'\n",
    "            relation = ''\n",
    "        else:\n",
    "            if current == 't':\n",
    "                subject += ' ' + token\n",
    "            elif current == 's':\n",
    "                object_ += ' ' + token\n",
    "            elif current == 'o':\n",
    "                relation += ' ' + token\n",
    "    if subject != '' and relation != '' and object_ != '':\n",
    "        triplets.append({'head': subject.strip(), 'type': relation.strip(),'tail': object_.strip()})\n",
    "\n",
    "    return triplets\n",
    "\n",
    "\n",
    "@Language.factory(\n",
    "    \"rebel\",\n",
    "    requires=[\"doc.sents\"],\n",
    "    assigns=[\"doc._.rel\"],\n",
    "    default_config={\n",
    "        \"model_name\": \"Babelscape/rebel-large\",\n",
    "        \"device\": 0,\n",
    "    },\n",
    ")\n",
    "class RebelComponent:\n",
    "    def __init__(\n",
    "        self,\n",
    "        nlp,\n",
    "        name,\n",
    "        model_name: str,\n",
    "        device: int,\n",
    "    ):\n",
    "        assert model_name is not None, \"\"\n",
    "        self.triplet_extractor = pipeline(\"text2text-generation\", model=model_name, tokenizer=model_name, device=device)\n",
    "        self.entity_mapping = {}\n",
    "        # Register custom extension on the Doc\n",
    "        if not Doc.has_extension(\"rel\"):\n",
    "            Doc.set_extension(\"rel\", default={})\n",
    "\n",
    "    def get_wiki_id(self, item: str):\n",
    "        mapping = self.entity_mapping.get(item)\n",
    "        if mapping:\n",
    "            return mapping\n",
    "        else:\n",
    "            res = call_wiki_api(item)\n",
    "            self.entity_mapping[item] = res\n",
    "            return res\n",
    "\n",
    "    \n",
    "    def _generate_triplets(self, sent: Span) -> List[dict]:\n",
    "        output_ids = self.triplet_extractor(sent.text, return_tensors=True, return_text=False)[0][\"generated_token_ids\"][\"output_ids\"]\n",
    "        extracted_text = self.triplet_extractor.tokenizer.batch_decode(output_ids[0])\n",
    "        extracted_triplets = extract_triplets(extracted_text[0])\n",
    "        return extracted_triplets\n",
    "\n",
    "    def set_annotations(self, doc: Doc, triplets: List[dict]):\n",
    "        for triplet in triplets:\n",
    "\n",
    "            # Remove self-loops (relationships that start and end at the entity)\n",
    "            if triplet['head'] == triplet['tail']:\n",
    "                continue\n",
    "\n",
    "            # Use regex to search for entities\n",
    "            head_span = re.search(triplet[\"head\"], doc.text)\n",
    "            tail_span = re.search(triplet[\"tail\"], doc.text)\n",
    "\n",
    "            # Skip the relation if both head and tail entities are not present in the text\n",
    "            # Sometimes the Rebel model hallucinates some entities\n",
    "            if not head_span or not tail_span:\n",
    "                continue\n",
    "\n",
    "            index = hashlib.sha1(\"\".join([triplet['head'], triplet['tail'], triplet['type']]).encode('utf-8')).hexdigest()\n",
    "            if index not in doc._.rel:\n",
    "                # Get wiki ids and store results\n",
    "                doc._.rel[index] = {\"relation\": triplet[\"type\"], \"head_span\": {'text': triplet['head'], 'id': self.get_wiki_id(triplet['head'])}, \"tail_span\": {'text': triplet['tail'], 'id': self.get_wiki_id(triplet['tail'])}}\n",
    "\n",
    "    def __call__(self, doc: Doc) -> Doc:\n",
    "        for sent in doc.sents:\n",
    "            sentence_triplets = self._generate_triplets(sent)\n",
    "            self.set_annotations(doc, sentence_triplets)\n",
    "        return doc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d1241c1d-d664-4897-9af5-87facc47b718",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "execution": {
     "iopub.execute_input": "2022-10-11T01:22:53.090141Z",
     "iopub.status.busy": "2022-10-11T01:22:53.089639Z",
     "iopub.status.idle": "2022-10-11T01:23:16.785428Z",
     "shell.execute_reply": "2022-10-11T01:23:16.784426Z",
     "shell.execute_reply.started": "2022-10-11T01:22:53.090141Z"
    },
    "id": "SSTDfj3nSSca",
    "outputId": "0dbdbb3c-7a6c-46a3-8b9e-dc89f8af7486",
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "error loading _jsonnet (this is expected on Windows), treating C:\\Users\\GCM\\AppData\\Local\\Temp\\tmpbcmi9qxu\\config.json as plain json\n",
      "Some weights of the model checkpoint at nreimers/mMiniLMv2-L12-H384-distilled-from-XLMR-Large were not used when initializing XLMRobertaModel: ['lm_head.bias', 'lm_head.dense.bias', 'lm_head.layer_norm.bias', 'lm_head.dense.weight', 'lm_head.layer_norm.weight']\n",
      "- This IS expected if you are initializing XLMRobertaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing XLMRobertaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of XLMRobertaModel were not initialized from the model checkpoint at nreimers/mMiniLMv2-L12-H384-distilled-from-XLMR-Large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<__main__.RebelComponent at 0x1fd103e3fd0>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "DEVICE = 0 # Number of the GPU, -1 if want to use CPU\n",
    "\n",
    "# Add coreference resolution model\n",
    "coref = spacy.load('en_core_web_sm', disable=['ner', 'tagger', 'parser', 'attribute_ruler', 'lemmatizer'])\n",
    "coref.add_pipe(\"xx_coref\", \n",
    "    config={\"chunk_size\": 2500, \n",
    "            \"chunk_overlap\": 2, \n",
    "            \"device\": DEVICE}\n",
    "              )\n",
    "\n",
    "# Define rel extraction model\n",
    "rel_ext = spacy.load('en_core_web_sm', disable=['ner', 'lemmatizer', 'attribute_rules', 'tagger'])\n",
    "rel_ext.add_pipe(\"rebel\", \n",
    "                 config={\n",
    "                     'device':DEVICE,\n",
    "                     'model_name':'Babelscape/rebel-large'} # Model used, will default to 'Babelscape/rebel-large' if not given\n",
    "                )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d5b0524a-a834-4e5f-995a-e20c9f5a2b97",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-10-11T01:23:16.787426Z",
     "iopub.status.busy": "2022-10-11T01:23:16.786927Z",
     "iopub.status.idle": "2022-10-11T01:23:16.800929Z",
     "shell.execute_reply": "2022-10-11T01:23:16.799927Z",
     "shell.execute_reply.started": "2022-10-11T01:23:16.787426Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# crosslingual_coreference implementation\n",
    "def coref_res(text_series):\n",
    "    coref_text_series = text_series.apply(lambda x : coref(x)._.resolved_text)\n",
    "    return(coref_text_series)\n",
    "\n",
    "# # choose minilm for speed/memory and info_xlm for accuracy\n",
    "# predictor = Predictor(\n",
    "#     language=\"en_core_web_sm\", device=-1, model_name=\"minilm\"\n",
    "# )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "35c9b2b0-fc17-4219-a3f2-7814f71e1c33",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-10-11T01:23:16.803443Z",
     "iopub.status.busy": "2022-10-11T01:23:16.802932Z",
     "iopub.status.idle": "2022-10-11T01:23:17.172511Z",
     "shell.execute_reply": "2022-10-11T01:23:17.171508Z",
     "shell.execute_reply.started": "2022-10-11T01:23:16.803443Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def link_entities_text(text):\n",
    "    try:\n",
    "        ent_rel_lst = list(rel_ext(text)._.rel.values())\n",
    "    except:\n",
    "        print(\"Could not extract relationships for text\")\n",
    "        ent_rel_lst = [{'relation': 'rel_err',\n",
    "                        'head_span': {'text': 'rel_err', 'id': 'rel_err'},\n",
    "                        'tail_span': {'text': 'rel_err', 'id': 'rel_err'}}]\n",
    "        \n",
    "    entity_df = pd.DataFrame()\n",
    "    rel_lst = []\n",
    "    head_text_lst = []\n",
    "    head_wiki_id_lst = []\n",
    "    tail_text_lst = []\n",
    "    tail_wiki_id_lst = []\n",
    "    for i in range(len(ent_rel_lst)):\n",
    "        rel_lst.append(ent_rel_lst[i]['relation'])\n",
    "        head_text_lst.append(ent_rel_lst[i]['head_span']['text'])\n",
    "        head_wiki_id_lst.append(ent_rel_lst[i]['head_span']['id'])\n",
    "        tail_text_lst.append(ent_rel_lst[i]['tail_span']['text'])\n",
    "        tail_wiki_id_lst.append(ent_rel_lst[i]['tail_span']['id'])\n",
    "    entity_df['head_text'] = head_text_lst\n",
    "    entity_df['head_wiki_id'] = head_wiki_id_lst\n",
    "    entity_df['relation'] = rel_lst\n",
    "    entity_df['tail_text'] = tail_text_lst\n",
    "    entity_df['tail_wiki_id'] = tail_wiki_id_lst\n",
    "    return(entity_df)\n",
    "\n",
    "def link_entities(text_series):\n",
    "    entity_df_series = text_series.apply(lambda x : link_entities_text(x))\n",
    "    return(entity_df_series)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "241dfc60-ff99-45d9-91cb-3638ff41236b",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-10-11T01:23:17.174009Z",
     "iopub.status.busy": "2022-10-11T01:23:17.173509Z",
     "iopub.status.idle": "2022-10-11T01:23:18.147053Z",
     "shell.execute_reply": "2022-10-11T01:23:18.146052Z",
     "shell.execute_reply.started": "2022-10-11T01:23:17.173509Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Authors</th>\n",
       "      <th>Author(s) ID</th>\n",
       "      <th>Title</th>\n",
       "      <th>Year</th>\n",
       "      <th>Source title</th>\n",
       "      <th>Volume</th>\n",
       "      <th>Issue</th>\n",
       "      <th>Art. No.</th>\n",
       "      <th>Page start</th>\n",
       "      <th>Page end</th>\n",
       "      <th>...</th>\n",
       "      <th>ISBN</th>\n",
       "      <th>CODEN</th>\n",
       "      <th>PubMed ID</th>\n",
       "      <th>Language of Original Document</th>\n",
       "      <th>Abbreviated Source Title</th>\n",
       "      <th>Document Type</th>\n",
       "      <th>Publication Stage</th>\n",
       "      <th>Open Access</th>\n",
       "      <th>Source</th>\n",
       "      <th>EID</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>MOORE D., PENIKAS J., RANKIN M.A.</td>\n",
       "      <td>55197635600;6504171017;7006868718;</td>\n",
       "      <td>Regional specialization for an optomotor respo...</td>\n",
       "      <td>1981.0</td>\n",
       "      <td>Physiological Entomology</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>61</td>\n",
       "      <td>69</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>English</td>\n",
       "      <td>Physiol.Entomol.</td>\n",
       "      <td>Article</td>\n",
       "      <td>Final</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Scopus</td>\n",
       "      <td>2-s2.0-84981620126</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Hoyle G.</td>\n",
       "      <td>7006576967;</td>\n",
       "      <td>The scope of neuroethology</td>\n",
       "      <td>1984.0</td>\n",
       "      <td>Behavioral and Brain Sciences</td>\n",
       "      <td>7</td>\n",
       "      <td>3</td>\n",
       "      <td>NaN</td>\n",
       "      <td>367</td>\n",
       "      <td>381</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>English</td>\n",
       "      <td>Behav. Brain Sci.</td>\n",
       "      <td>Article</td>\n",
       "      <td>Final</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Scopus</td>\n",
       "      <td>2-s2.0-84973935944</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Skinner B.F.</td>\n",
       "      <td>7005596882;</td>\n",
       "      <td>Selection by consequences</td>\n",
       "      <td>1984.0</td>\n",
       "      <td>Behavioral and Brain Sciences</td>\n",
       "      <td>7</td>\n",
       "      <td>4</td>\n",
       "      <td>NaN</td>\n",
       "      <td>477</td>\n",
       "      <td>481</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>English</td>\n",
       "      <td>Behav. Brain Sci.</td>\n",
       "      <td>Article</td>\n",
       "      <td>Final</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Scopus</td>\n",
       "      <td>2-s2.0-84971114253</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Menzel R., Greggers U.</td>\n",
       "      <td>7102000725;6506245498;</td>\n",
       "      <td>Natural phototaxis and its relationship to col...</td>\n",
       "      <td>1985.0</td>\n",
       "      <td>Journal of Comparative Physiology A</td>\n",
       "      <td>157</td>\n",
       "      <td>3</td>\n",
       "      <td>NaN</td>\n",
       "      <td>311</td>\n",
       "      <td>321</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>JCPAD</td>\n",
       "      <td>NaN</td>\n",
       "      <td>English</td>\n",
       "      <td>J. Comp. Physiol.</td>\n",
       "      <td>Article</td>\n",
       "      <td>Final</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Scopus</td>\n",
       "      <td>2-s2.0-0006976113</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Brill J.H., Mayfield H.T., Mar T., Bertsch W.</td>\n",
       "      <td>7103055208;6603702494;24427642600;7004578956;</td>\n",
       "      <td>Use of computerized pattern recognition in the...</td>\n",
       "      <td>1985.0</td>\n",
       "      <td>Journal of Chromatography A</td>\n",
       "      <td>349</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>31</td>\n",
       "      <td>38</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>JCRAE</td>\n",
       "      <td>4086644.0</td>\n",
       "      <td>English</td>\n",
       "      <td>J. Chromatogr. A</td>\n",
       "      <td>Article</td>\n",
       "      <td>Final</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Scopus</td>\n",
       "      <td>2-s2.0-0022420221</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3832</th>\n",
       "      <td>Pian C., Mao S., Zhang G., Du J., Li F., Leung...</td>\n",
       "      <td>56181512400;57202392306;57189468170;5721520425...</td>\n",
       "      <td>Discovering Cancer-Related miRNAs from miRNA-T...</td>\n",
       "      <td>2020.0</td>\n",
       "      <td>Molecular Therapy - Nucleic Acids</td>\n",
       "      <td>19</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1423</td>\n",
       "      <td>1433</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>English</td>\n",
       "      <td>Mol. Ther. Nucl. Acids</td>\n",
       "      <td>Article</td>\n",
       "      <td>Final</td>\n",
       "      <td>All Open Access, Gold, Green</td>\n",
       "      <td>Scopus</td>\n",
       "      <td>2-s2.0-85080101579</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3833</th>\n",
       "      <td>Bleker J., Kwee T.C., Dierckx R.A.J.O., de Jon...</td>\n",
       "      <td>57212091754;16432912900;7102816622;7005938218;...</td>\n",
       "      <td>Multiparametric MRI and auto-fixed volume of i...</td>\n",
       "      <td>2020.0</td>\n",
       "      <td>European Radiology</td>\n",
       "      <td>30</td>\n",
       "      <td>3</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1313</td>\n",
       "      <td>1324</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>EURAE</td>\n",
       "      <td>31776744.0</td>\n",
       "      <td>English</td>\n",
       "      <td>Eur. Radiol.</td>\n",
       "      <td>Article</td>\n",
       "      <td>Final</td>\n",
       "      <td>All Open Access, Hybrid Gold, Green</td>\n",
       "      <td>Scopus</td>\n",
       "      <td>2-s2.0-85075888221</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3834</th>\n",
       "      <td>Jose V S., Nameer P.O.</td>\n",
       "      <td>57211856052;6507739308;</td>\n",
       "      <td>The expanding distribution of the Indian Peafo...</td>\n",
       "      <td>2020.0</td>\n",
       "      <td>Ecological Indicators</td>\n",
       "      <td>110</td>\n",
       "      <td>NaN</td>\n",
       "      <td>105930</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>English</td>\n",
       "      <td>Ecol. Indic.</td>\n",
       "      <td>Article</td>\n",
       "      <td>Final</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Scopus</td>\n",
       "      <td>2-s2.0-85075189322</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3835</th>\n",
       "      <td>Kaszubinski S.F., Pechal J.L., Schmidt C.J., J...</td>\n",
       "      <td>57211628505;35272981100;35493831100;5698254900...</td>\n",
       "      <td>Evaluating Bioinformatic Pipeline Performance ...</td>\n",
       "      <td>2020.0</td>\n",
       "      <td>Journal of Forensic Sciences</td>\n",
       "      <td>65</td>\n",
       "      <td>2</td>\n",
       "      <td>NaN</td>\n",
       "      <td>513</td>\n",
       "      <td>525</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>JFSCA</td>\n",
       "      <td>31657871.0</td>\n",
       "      <td>English</td>\n",
       "      <td>J. Forensic Sci.</td>\n",
       "      <td>Article</td>\n",
       "      <td>Final</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Scopus</td>\n",
       "      <td>2-s2.0-85074669672</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3836</th>\n",
       "      <td>Sun J., Qiu H., Guo J., Xu X., Wu D., Zhong L....</td>\n",
       "      <td>57217995781;57211626106;57209733754;5721101466...</td>\n",
       "      <td>Modeling the potential distribution of Zelkova...</td>\n",
       "      <td>2020.0</td>\n",
       "      <td>Global Ecology and Conservation</td>\n",
       "      <td>21</td>\n",
       "      <td>NaN</td>\n",
       "      <td>e00840</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>English</td>\n",
       "      <td>Glob. Ecol. Conserv.</td>\n",
       "      <td>Article</td>\n",
       "      <td>Final</td>\n",
       "      <td>All Open Access, Gold</td>\n",
       "      <td>Scopus</td>\n",
       "      <td>2-s2.0-85074654128</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3837 rows × 54 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                Authors  \\\n",
       "0                     MOORE D., PENIKAS J., RANKIN M.A.   \n",
       "1                                              Hoyle G.   \n",
       "2                                          Skinner B.F.   \n",
       "3                                Menzel R., Greggers U.   \n",
       "4         Brill J.H., Mayfield H.T., Mar T., Bertsch W.   \n",
       "...                                                 ...   \n",
       "3832  Pian C., Mao S., Zhang G., Du J., Li F., Leung...   \n",
       "3833  Bleker J., Kwee T.C., Dierckx R.A.J.O., de Jon...   \n",
       "3834                             Jose V S., Nameer P.O.   \n",
       "3835  Kaszubinski S.F., Pechal J.L., Schmidt C.J., J...   \n",
       "3836  Sun J., Qiu H., Guo J., Xu X., Wu D., Zhong L....   \n",
       "\n",
       "                                           Author(s) ID  \\\n",
       "0                    55197635600;6504171017;7006868718;   \n",
       "1                                           7006576967;   \n",
       "2                                           7005596882;   \n",
       "3                                7102000725;6506245498;   \n",
       "4         7103055208;6603702494;24427642600;7004578956;   \n",
       "...                                                 ...   \n",
       "3832  56181512400;57202392306;57189468170;5721520425...   \n",
       "3833  57212091754;16432912900;7102816622;7005938218;...   \n",
       "3834                            57211856052;6507739308;   \n",
       "3835  57211628505;35272981100;35493831100;5698254900...   \n",
       "3836  57217995781;57211626106;57209733754;5721101466...   \n",
       "\n",
       "                                                  Title    Year  \\\n",
       "0     Regional specialization for an optomotor respo...  1981.0   \n",
       "1                            The scope of neuroethology  1984.0   \n",
       "2                             Selection by consequences  1984.0   \n",
       "3     Natural phototaxis and its relationship to col...  1985.0   \n",
       "4     Use of computerized pattern recognition in the...  1985.0   \n",
       "...                                                 ...     ...   \n",
       "3832  Discovering Cancer-Related miRNAs from miRNA-T...  2020.0   \n",
       "3833  Multiparametric MRI and auto-fixed volume of i...  2020.0   \n",
       "3834  The expanding distribution of the Indian Peafo...  2020.0   \n",
       "3835  Evaluating Bioinformatic Pipeline Performance ...  2020.0   \n",
       "3836  Modeling the potential distribution of Zelkova...  2020.0   \n",
       "\n",
       "                             Source title Volume Issue Art. No. Page start  \\\n",
       "0                Physiological Entomology      6     1      NaN         61   \n",
       "1           Behavioral and Brain Sciences      7     3      NaN        367   \n",
       "2           Behavioral and Brain Sciences      7     4      NaN        477   \n",
       "3     Journal of Comparative Physiology A    157     3      NaN        311   \n",
       "4             Journal of Chromatography A    349     1      NaN         31   \n",
       "...                                   ...    ...   ...      ...        ...   \n",
       "3832    Molecular Therapy - Nucleic Acids     19   NaN      NaN       1423   \n",
       "3833                   European Radiology     30     3      NaN       1313   \n",
       "3834                Ecological Indicators    110   NaN   105930        NaN   \n",
       "3835         Journal of Forensic Sciences     65     2      NaN        513   \n",
       "3836      Global Ecology and Conservation     21   NaN   e00840        NaN   \n",
       "\n",
       "     Page end  ... ISBN  CODEN   PubMed ID Language of Original Document  \\\n",
       "0          69  ...  NaN    NaN         NaN                       English   \n",
       "1         381  ...  NaN    NaN         NaN                       English   \n",
       "2         481  ...  NaN    NaN         NaN                       English   \n",
       "3         321  ...  NaN  JCPAD         NaN                       English   \n",
       "4          38  ...  NaN  JCRAE   4086644.0                       English   \n",
       "...       ...  ...  ...    ...         ...                           ...   \n",
       "3832     1433  ...  NaN    NaN         NaN                       English   \n",
       "3833     1324  ...  NaN  EURAE  31776744.0                       English   \n",
       "3834      NaN  ...  NaN    NaN         NaN                       English   \n",
       "3835      525  ...  NaN  JFSCA  31657871.0                       English   \n",
       "3836      NaN  ...  NaN    NaN         NaN                       English   \n",
       "\n",
       "     Abbreviated Source Title Document Type Publication Stage  \\\n",
       "0            Physiol.Entomol.       Article             Final   \n",
       "1           Behav. Brain Sci.       Article             Final   \n",
       "2           Behav. Brain Sci.       Article             Final   \n",
       "3           J. Comp. Physiol.       Article             Final   \n",
       "4            J. Chromatogr. A       Article             Final   \n",
       "...                       ...           ...               ...   \n",
       "3832   Mol. Ther. Nucl. Acids       Article             Final   \n",
       "3833             Eur. Radiol.       Article             Final   \n",
       "3834             Ecol. Indic.       Article             Final   \n",
       "3835         J. Forensic Sci.       Article             Final   \n",
       "3836     Glob. Ecol. Conserv.       Article             Final   \n",
       "\n",
       "                              Open Access  Source                 EID  \n",
       "0                                     NaN  Scopus  2-s2.0-84981620126  \n",
       "1                                     NaN  Scopus  2-s2.0-84973935944  \n",
       "2                                     NaN  Scopus  2-s2.0-84971114253  \n",
       "3                                     NaN  Scopus   2-s2.0-0006976113  \n",
       "4                                     NaN  Scopus   2-s2.0-0022420221  \n",
       "...                                   ...     ...                 ...  \n",
       "3832         All Open Access, Gold, Green  Scopus  2-s2.0-85080101579  \n",
       "3833  All Open Access, Hybrid Gold, Green  Scopus  2-s2.0-85075888221  \n",
       "3834                                  NaN  Scopus  2-s2.0-85075189322  \n",
       "3835                                  NaN  Scopus  2-s2.0-85074669672  \n",
       "3836                All Open Access, Gold  Scopus  2-s2.0-85074654128  \n",
       "\n",
       "[3837 rows x 54 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_df = pd.read_csv('E:\\\\GIT_REPOS\\\\LAB\\\\Literature_summary\\\\Test\\\\Entity_edgelist\\\\Input\\\\entomology-machine-learning-csv.csv')\n",
    "# data_df = data_df.drop('File', axis=1)\n",
    "data_df = data_df.drop_duplicates().reset_index(drop=True)\n",
    "data_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "90b2f9c9-0580-4015-a0d5-f61738c54de1",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-10-11T01:23:18.149555Z",
     "iopub.status.busy": "2022-10-11T01:23:18.149055Z",
     "iopub.status.idle": "2022-10-11T01:23:18.209050Z",
     "shell.execute_reply": "2022-10-11T01:23:18.208050Z",
     "shell.execute_reply.started": "2022-10-11T01:23:18.149555Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\GCM\\AppData\\Local\\Temp\\ipykernel_25880\\412532311.py:5: FutureWarning: The default value of regex will change from True to False in a future version. In addition, single character regular expressions will *not* be treated as literal strings when regex=True.\n",
      "  data_df[\"Abstract\"] = data_df[\"Abstract\"].str.replace(r'(', '')\n",
      "C:\\Users\\GCM\\AppData\\Local\\Temp\\ipykernel_25880\\412532311.py:6: FutureWarning: The default value of regex will change from True to False in a future version. In addition, single character regular expressions will *not* be treated as literal strings when regex=True.\n",
      "  data_df[\"Abstract\"] = data_df[\"Abstract\"].str.replace(r')', '')\n"
     ]
    }
   ],
   "source": [
    "# import data\n",
    "# data_df = pd.read_csv('E:\\GIT_REPOS\\LAB\\Literature_summary\\TPN\\Papers\\\\scopus.csv')\n",
    "data_df = data_df[data_df[\"Abstract\"] != '[No abstract available]']\n",
    "data_df.reset_index(inplace=True, drop=True)\n",
    "data_df[\"Abstract\"] = data_df[\"Abstract\"].str.replace(r'(', '')\n",
    "data_df[\"Abstract\"] = data_df[\"Abstract\"].str.replace(r')', '')\n",
    "data_df[\"Abstract\"] = data_df[\"Abstract\"].str.replace(r\"'\", '')\n",
    "data_df[\"Abstract\"] = data_df[\"Abstract\"].str.replace(r\"'\", '')\n",
    "data_df[\"Abstract\"] = data_df[\"Abstract\"].str.replace(r'\"', '')\n",
    "data_df[\"Abstract\"] = data_df[\"Abstract\"].str.replace(r'\"', '')\n",
    "data_df[\"Abstract\"] = data_df[\"Abstract\"].astype(str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "8d36c245-8c59-4c34-8ec0-f4661faf0cf6",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-10-11T01:23:18.210552Z",
     "iopub.status.busy": "2022-10-11T01:23:18.210053Z",
     "iopub.status.idle": "2022-10-11T05:34:54.789496Z",
     "shell.execute_reply": "2022-10-11T05:34:54.787996Z",
     "shell.execute_reply.started": "2022-10-11T01:23:18.210552Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "coref done 0\n",
      "entity linking done 0\n",
      "df create done 0\n",
      "df to list done 0 \n",
      "\n",
      "coref done 100\n",
      "entity linking done 100\n",
      "df create done 100\n",
      "df to list done 100 \n",
      "\n",
      "coref done 200\n",
      "entity linking done 200\n",
      "df create done 200\n",
      "df to list done 200 \n",
      "\n",
      "coref done 300\n",
      "entity linking done 300\n",
      "df create done 300\n",
      "df to list done 300 \n",
      "\n",
      "coref done 400\n",
      "entity linking done 400\n",
      "df create done 400\n",
      "df to list done 400 \n",
      "\n",
      "coref done 500\n",
      "entity linking done 500\n",
      "df create done 500\n",
      "df to list done 500 \n",
      "\n",
      "coref done 600\n",
      "entity linking done 600\n",
      "df create done 600\n",
      "df to list done 600 \n",
      "\n",
      "coref done 700\n",
      "entity linking done 700\n",
      "df create done 700\n",
      "df to list done 700 \n",
      "\n",
      "coref done 800\n",
      "entity linking done 800\n",
      "df create done 800\n",
      "df to list done 800 \n",
      "\n",
      "coref done 900\n",
      "entity linking done 900\n",
      "df create done 900\n",
      "df to list done 900 \n",
      "\n",
      "coref done 1000\n",
      "entity linking done 1000\n",
      "df create done 1000\n",
      "df to list done 1000 \n",
      "\n",
      "coref done 1100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\GCM\\AppData\\Local\\Temp\\ipykernel_25880\\4235504974.py:94: FutureWarning: Possible nested set at position 6\n",
      "  head_span = re.search(triplet[\"head\"], doc.text)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Could not extract relationships for text\n",
      "entity linking done 1100\n",
      "df create done 1100\n",
      "df to list done 1100 \n",
      "\n",
      "coref done 1200\n",
      "Could not extract relationships for text\n",
      "entity linking done 1200\n",
      "df create done 1200\n",
      "df to list done 1200 \n",
      "\n",
      "coref done 1300\n",
      "entity linking done 1300\n",
      "df create done 1300\n",
      "df to list done 1300 \n",
      "\n",
      "coref done 1400\n",
      "entity linking done 1400\n",
      "df create done 1400\n",
      "df to list done 1400 \n",
      "\n",
      "coref done 1500\n",
      "entity linking done 1500\n",
      "df create done 1500\n",
      "df to list done 1500 \n",
      "\n",
      "coref done 1600\n",
      "entity linking done 1600\n",
      "df create done 1600\n",
      "df to list done 1600 \n",
      "\n",
      "coref done 1700\n",
      "entity linking done 1700\n",
      "df create done 1700\n",
      "df to list done 1700 \n",
      "\n",
      "coref done 1800\n",
      "entity linking done 1800\n",
      "df create done 1800\n",
      "df to list done 1800 \n",
      "\n",
      "coref done 1900\n",
      "entity linking done 1900\n",
      "df create done 1900\n",
      "df to list done 1900 \n",
      "\n",
      "coref done 2000\n",
      "entity linking done 2000\n",
      "df create done 2000\n",
      "df to list done 2000 \n",
      "\n",
      "coref done 2100\n",
      "Could not extract relationships for text\n",
      "entity linking done 2100\n",
      "df create done 2100\n",
      "df to list done 2100 \n",
      "\n",
      "coref done 2200\n",
      "entity linking done 2200\n",
      "df create done 2200\n",
      "df to list done 2200 \n",
      "\n"
     ]
    },
    {
     "ename": "IndexError",
     "evalue": "list index out of range",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "Input \u001b[1;32mIn [8]\u001b[0m, in \u001b[0;36m<cell line: 5>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      4\u001b[0m entities_df_lst \u001b[38;5;241m=\u001b[39m []\n\u001b[0;32m      5\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(start_point, \u001b[38;5;28mlen\u001b[39m(data_df), win_size):\n\u001b[1;32m----> 6\u001b[0m     coref_series \u001b[38;5;241m=\u001b[39m \u001b[43mcoref_res\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtext_series\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdata_df\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mAbstract\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43miloc\u001b[49m\u001b[43m[\u001b[49m\u001b[43mi\u001b[49m\u001b[43m:\u001b[49m\u001b[43mi\u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[43mwin_size\u001b[49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m      7\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcoref done\u001b[39m\u001b[38;5;124m'\u001b[39m, i)\n\u001b[0;32m      8\u001b[0m     link_entities_series \u001b[38;5;241m=\u001b[39m link_entities(text_series\u001b[38;5;241m=\u001b[39mcoref_series)\n",
      "Input \u001b[1;32mIn [4]\u001b[0m, in \u001b[0;36mcoref_res\u001b[1;34m(text_series)\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mcoref_res\u001b[39m(text_series):\n\u001b[1;32m----> 3\u001b[0m     coref_text_series \u001b[38;5;241m=\u001b[39m \u001b[43mtext_series\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mapply\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43;01mlambda\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mx\u001b[49m\u001b[43m \u001b[49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mcoref\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mresolved_text\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m      4\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m(coref_text_series)\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\kg\\lib\\site-packages\\pandas\\core\\series.py:4774\u001b[0m, in \u001b[0;36mSeries.apply\u001b[1;34m(self, func, convert_dtype, args, **kwargs)\u001b[0m\n\u001b[0;32m   4664\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mapply\u001b[39m(\n\u001b[0;32m   4665\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[0;32m   4666\u001b[0m     func: AggFuncType,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   4669\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs,\n\u001b[0;32m   4670\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m DataFrame \u001b[38;5;241m|\u001b[39m Series:\n\u001b[0;32m   4671\u001b[0m     \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m   4672\u001b[0m \u001b[38;5;124;03m    Invoke function on values of Series.\u001b[39;00m\n\u001b[0;32m   4673\u001b[0m \n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   4772\u001b[0m \u001b[38;5;124;03m    dtype: float64\u001b[39;00m\n\u001b[0;32m   4773\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m-> 4774\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mSeriesApply\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfunc\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mconvert_dtype\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mapply\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\kg\\lib\\site-packages\\pandas\\core\\apply.py:1100\u001b[0m, in \u001b[0;36mSeriesApply.apply\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   1097\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mapply_str()\n\u001b[0;32m   1099\u001b[0m \u001b[38;5;66;03m# self.f is Callable\u001b[39;00m\n\u001b[1;32m-> 1100\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mapply_standard\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\kg\\lib\\site-packages\\pandas\\core\\apply.py:1151\u001b[0m, in \u001b[0;36mSeriesApply.apply_standard\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   1149\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m   1150\u001b[0m         values \u001b[38;5;241m=\u001b[39m obj\u001b[38;5;241m.\u001b[39mastype(\u001b[38;5;28mobject\u001b[39m)\u001b[38;5;241m.\u001b[39m_values\n\u001b[1;32m-> 1151\u001b[0m         mapped \u001b[38;5;241m=\u001b[39m \u001b[43mlib\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmap_infer\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   1152\u001b[0m \u001b[43m            \u001b[49m\u001b[43mvalues\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1153\u001b[0m \u001b[43m            \u001b[49m\u001b[43mf\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1154\u001b[0m \u001b[43m            \u001b[49m\u001b[43mconvert\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconvert_dtype\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1155\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1157\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(mapped) \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(mapped[\u001b[38;5;241m0\u001b[39m], ABCSeries):\n\u001b[0;32m   1158\u001b[0m     \u001b[38;5;66;03m# GH#43986 Need to do list(mapped) in order to get treated as nested\u001b[39;00m\n\u001b[0;32m   1159\u001b[0m     \u001b[38;5;66;03m#  See also GH#25959 regarding EA support\u001b[39;00m\n\u001b[0;32m   1160\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m obj\u001b[38;5;241m.\u001b[39m_constructor_expanddim(\u001b[38;5;28mlist\u001b[39m(mapped), index\u001b[38;5;241m=\u001b[39mobj\u001b[38;5;241m.\u001b[39mindex)\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\kg\\lib\\site-packages\\pandas\\_libs\\lib.pyx:2919\u001b[0m, in \u001b[0;36mpandas._libs.lib.map_infer\u001b[1;34m()\u001b[0m\n",
      "Input \u001b[1;32mIn [4]\u001b[0m, in \u001b[0;36mcoref_res.<locals>.<lambda>\u001b[1;34m(x)\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mcoref_res\u001b[39m(text_series):\n\u001b[1;32m----> 3\u001b[0m     coref_text_series \u001b[38;5;241m=\u001b[39m text_series\u001b[38;5;241m.\u001b[39mapply(\u001b[38;5;28;01mlambda\u001b[39;00m x : \u001b[43mcoref\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241m.\u001b[39m_\u001b[38;5;241m.\u001b[39mresolved_text)\n\u001b[0;32m      4\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m(coref_text_series)\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\kg\\lib\\site-packages\\spacy\\language.py:1025\u001b[0m, in \u001b[0;36mLanguage.__call__\u001b[1;34m(self, text, disable, component_cfg)\u001b[0m\n\u001b[0;32m   1023\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(Errors\u001b[38;5;241m.\u001b[39mE109\u001b[38;5;241m.\u001b[39mformat(name\u001b[38;5;241m=\u001b[39mname)) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01me\u001b[39;00m\n\u001b[0;32m   1024\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m-> 1025\u001b[0m     \u001b[43merror_handler\u001b[49m\u001b[43m(\u001b[49m\u001b[43mname\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mproc\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m[\u001b[49m\u001b[43mdoc\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43me\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1026\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m doc \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m   1027\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(Errors\u001b[38;5;241m.\u001b[39mE005\u001b[38;5;241m.\u001b[39mformat(name\u001b[38;5;241m=\u001b[39mname))\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\kg\\lib\\site-packages\\spacy\\util.py:1658\u001b[0m, in \u001b[0;36mraise_error\u001b[1;34m(proc_name, proc, docs, e)\u001b[0m\n\u001b[0;32m   1657\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mraise_error\u001b[39m(proc_name, proc, docs, e):\n\u001b[1;32m-> 1658\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m e\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\kg\\lib\\site-packages\\spacy\\language.py:1020\u001b[0m, in \u001b[0;36mLanguage.__call__\u001b[1;34m(self, text, disable, component_cfg)\u001b[0m\n\u001b[0;32m   1018\u001b[0m     error_handler \u001b[38;5;241m=\u001b[39m proc\u001b[38;5;241m.\u001b[39mget_error_handler()\n\u001b[0;32m   1019\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m-> 1020\u001b[0m     doc \u001b[38;5;241m=\u001b[39m proc(doc, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mcomponent_cfg\u001b[38;5;241m.\u001b[39mget(name, {}))  \u001b[38;5;66;03m# type: ignore[call-arg]\u001b[39;00m\n\u001b[0;32m   1021\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m   1022\u001b[0m     \u001b[38;5;66;03m# This typically happens if a component is not initialized\u001b[39;00m\n\u001b[0;32m   1023\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(Errors\u001b[38;5;241m.\u001b[39mE109\u001b[38;5;241m.\u001b[39mformat(name\u001b[38;5;241m=\u001b[39mname)) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01me\u001b[39;00m\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\kg\\lib\\site-packages\\crosslingual_coreference\\CrossLingualPredictorSpacy.py:33\u001b[0m, in \u001b[0;36mCrossLingualPredictorSpacy.__call__\u001b[1;34m(self, doc)\u001b[0m\n\u001b[0;32m     23\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__call__\u001b[39m(\u001b[38;5;28mself\u001b[39m, doc: Doc) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Doc:\n\u001b[0;32m     24\u001b[0m     \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m     25\u001b[0m \u001b[38;5;124;03m    predict the class for a spacy Doc\u001b[39;00m\n\u001b[0;32m     26\u001b[0m \n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     31\u001b[0m \u001b[38;5;124;03m        Doc: spacy doc with ._.cats key-class proba-value dict\u001b[39;00m\n\u001b[0;32m     32\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m---> 33\u001b[0m     prediction \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[38;5;18;43m__class__\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpredict\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdoc\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtext\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     34\u001b[0m     doc \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39massign_prediction_to_doc(doc, prediction)\n\u001b[0;32m     35\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m doc\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\kg\\lib\\site-packages\\crosslingual_coreference\\CrossLingualPredictor.py:105\u001b[0m, in \u001b[0;36mCrossLingualPredictor.predict\u001b[1;34m(self, text)\u001b[0m\n\u001b[0;32m    103\u001b[0m doc \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpredictor\u001b[38;5;241m.\u001b[39m_spacy(text)\n\u001b[0;32m    104\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mchunk_size:\n\u001b[1;32m--> 105\u001b[0m     chunks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mchunk_sentencized_doc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdoc\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    106\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    107\u001b[0m     chunks \u001b[38;5;241m=\u001b[39m [text]\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\kg\\lib\\site-packages\\crosslingual_coreference\\CrossLingualPredictor.py:193\u001b[0m, in \u001b[0;36mCrossLingualPredictor.chunk_sentencized_doc\u001b[1;34m(self, doc)\u001b[0m\n\u001b[0;32m    191\u001b[0m \u001b[38;5;66;03m# Check if the last chunk is too short. If it is, add it to the previous chunk\u001b[39;00m\n\u001b[0;32m    192\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(temp_chunk) \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m1\u001b[39m \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(temp_chunk[\u001b[38;5;241m0\u001b[39m]) \u001b[38;5;241m<\u001b[39m \u001b[38;5;241m3\u001b[39m:\n\u001b[1;32m--> 193\u001b[0m     \u001b[43mresult\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m-\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m]\u001b[49m\u001b[38;5;241m.\u001b[39mextend(temp_chunk[:])\n\u001b[0;32m    194\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    195\u001b[0m     result\u001b[38;5;241m.\u001b[39mappend(temp_chunk[:])\n",
      "\u001b[1;31mIndexError\u001b[0m: list index out of range"
     ]
    }
   ],
   "source": [
    "win_size = 100\n",
    "start_point = 0 # default to 0\n",
    "# coref_lst = []\n",
    "entities_df_lst = []\n",
    "for i in range(start_point, len(data_df), win_size):\n",
    "    coref_series = coref_res(text_series=data_df[\"Abstract\"].iloc[i:i+win_size])\n",
    "    print('coref done', i)\n",
    "    link_entities_series = link_entities(text_series=coref_series)\n",
    "    print('entity linking done', i)\n",
    "    entities_df = pd.concat(link_entities_series.tolist())\n",
    "    print('df create done', i)\n",
    "    entities_df_lst.append(entities_df)\n",
    "    print('df to list done', i, '\\n')\n",
    "all_entities_df = pd.concat(entities_df_lst)\n",
    "all_entities_df.reset_index(drop=True, inplace=True)\n",
    "edge_lst_df = all_entities_df.value_counts().reset_index().rename(columns={0: \"count\"})\n",
    "edge_lst_df.to_csv('entity_weighted_edgelist_entemology_ML.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d3babaf-6763-4262-9bab-116ad5a4419e",
   "metadata": {
    "execution": {
     "iopub.status.busy": "2022-10-11T05:34:54.790497Z",
     "iopub.status.idle": "2022-10-11T05:34:54.790996Z",
     "shell.execute_reply": "2022-10-11T05:34:54.790497Z",
     "shell.execute_reply.started": "2022-10-11T05:34:54.790497Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# coref_series = coref_res(text_series=data_df[\"Abstract\"][:1000])\n",
    "# link_entities_series = link_entities(text_series=coref_series)\n",
    "# all_entities_df = pd.concat(link_entities_series.tolist())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
